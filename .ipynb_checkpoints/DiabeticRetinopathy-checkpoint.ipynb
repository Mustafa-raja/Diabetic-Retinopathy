{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Statistics of data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9da8ae26acb897f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "level\n0    25810\n1     2443\n2     5292\n3      873\n4      708\ndtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  pandas as pd\n",
    "df15 = pd.read_csv(\"trainLabels15.csv\")\n",
    "df_pivot = df15.pivot(columns='level', values='image')\n",
    "df_pivot.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T02:34:39.410200Z",
     "start_time": "2024-05-04T02:34:39.254248Z"
    }
   },
   "id": "b236d3c0a3113451",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "diagnosis\n0    1805\n1     370\n2     999\n3     193\n4     295\ndtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df19 = pd.read_csv(\"trainLabels19.csv\")\n",
    "df_pivot = df19.pivot(columns='diagnosis', values='id_code')\n",
    "df_pivot.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T02:34:43.411034Z",
     "start_time": "2024-05-04T02:34:43.358544Z"
    }
   },
   "id": "3abe081af5b5c728",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data exhibits a class imbalance, where class 0 has a significantly higher number of images compared to classes 1, 2, 3, and 4. This can negatively impact machine learning models by causing them to favor the majority class (class 0) during training.\n",
    "\n",
    "### Addressing Class Imbalance\n",
    "The proposed strategy to counter this imbalance is to rotate the images in classes 1, 2, 3, and 4. This would create new images that could be added to respective classes. Specifically, the strategy suggests rotating the images by 90 degrees, 180 degrees, and 270 degrees. This would triple the number of images in each of the classes being rotated.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cb86e5c3b39c620"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merging 2019 and 2015 datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8a027cf5e9cb867"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             image  level\n0     000c1434d8d7      2\n1     001639a390f0      4\n2     0024cdab0c1e      1\n3     002c21358ce6      0\n4     005b95c28852      0\n...            ...    ...\n3657  ffa47f6a7bf4      2\n3658  ffc04fed30e6      0\n3659  ffcf7b45f213      2\n3660  ffd97f8cd5aa      0\n3661  ffec9a18a3ce      2\n\n[3662 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000c1434d8d7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001639a390f0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0024cdab0c1e</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>002c21358ce6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>005b95c28852</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3657</th>\n      <td>ffa47f6a7bf4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3658</th>\n      <td>ffc04fed30e6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3659</th>\n      <td>ffcf7b45f213</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3660</th>\n      <td>ffd97f8cd5aa</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3661</th>\n      <td>ffec9a18a3ce</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>3662 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df19.rename(columns = {'id_code':'image', 'diagnosis':'level'}, inplace = True)\n",
    "df19"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T02:34:52.519985Z",
     "start_time": "2024-05-04T02:34:52.495718Z"
    }
   },
   "id": "fbf5a647ff69e3ec",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "level\n0    27615\n1     2813\n2     6291\n3     1066\n4     1003\ndtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df15, df19, how='outer')\n",
    "df_pivot = df.pivot(columns='level', values='image')\n",
    "df_pivot.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T02:35:12.825717Z",
     "start_time": "2024-05-04T02:35:12.752888Z"
    }
   },
   "id": "79698d4ee28ac06c",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datasets\n",
    "The two datasets are now merged in one dataframe\n",
    "further actions\n",
    "- **Generate CSV**: Create a CSV file containing the merged dataframe for easy access and reference.\n",
    "- **Organizing the images**: Organize the images into their respective directories based on their class labels for efficient management and access.\n",
    "- **Augmentation of Images**: Rotate images belonging to classes 1, 2, 3, and 4 to counter the imbalance within these classes, ensuring a more balanced representation across all classes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a6c9545cb0fb0e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.to_csv(\"train19&15.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T02:35:18.874084Z",
     "start_time": "2024-05-04T02:35:18.812632Z"
    }
   },
   "id": "5ecc26a432af21e1",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_Images = df['image'].count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T02:37:19.037219Z",
     "start_time": "2024-05-04T02:37:19.006134Z"
    }
   },
   "id": "451aef3af21a83f9",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Dividing images to respective directories according to their classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1f8e53633bd29e5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/38788 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63950a791540443f864b50579c53b69c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "for label in df['level'].unique():\n",
    "    class_dir = os.path.join('class ' + str(label))\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.makedirs(class_dir)\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    image_name = row['image'] + '.jpg'\n",
    "    class_label = row['level']\n",
    "\n",
    "    for directory in ['../../../Downloads/archive/resized train 15', '../../../Downloads/archive/resized train 19']:\n",
    "        if image_name in os.listdir(directory):\n",
    "            image_to_copy = os.path.join(directory, image_name)\n",
    "            destination = os.path.join('class ' + str(class_label))\n",
    "            shutil.copy(image_to_copy, destination)\n",
    "            break\n",
    "        if directory == '../../../Downloads/archive/resized train 19':\n",
    "            print(\"IMAGE NOT FOUND\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T03:38:18.920558Z",
     "start_time": "2024-05-04T02:45:55.425171Z"
    }
   },
   "id": "450d56b1ee55192f",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Augmenting the images of class 1, 2, 3, 4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5408c80eaae41ca5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/11173 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01f723569d284c1c9ba1554f834d2283"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "\n",
    "Augmenting_df = df[df['level'] != 0]\n",
    "Augmented_df = df\n",
    "\n",
    "for index, row in tqdm(Augmenting_df.iterrows(), total = len(Augmenting_df)):\n",
    "    image_name = row['image'] + '.jpg'\n",
    "    class_label = row['level']\n",
    "    directory = 'class ' + str(class_label)\n",
    "    Original_Image = cv2.imread(str(os.path.join(directory, image_name)))\n",
    "    rotated_image1 = cv2.rotate(Original_Image, cv2.ROTATE_180)\n",
    "    rotated_image2 = cv2.rotate(Original_Image, cv2.ROTATE_90_CLOCKWISE)\n",
    "    rotated_image3 = cv2.rotate(Original_Image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    for image, name in [(rotated_image1, row['image'] + '_rotate180'), (rotated_image2, row['image'] + '_rotate270' ),\n",
    "                        (rotated_image3, row['image'] + '_rotate90')]:\n",
    "         \n",
    "        new_index= Augmented_df.index[-1] + 1\n",
    "        rotated_row = pd.DataFrame({'image' : name, 'level' : class_label}, index = [new_index] )\n",
    "        Augmented_df = pd.merge(Augmented_df, rotated_row, how='outer')\n",
    "        cv2.imwrite(str(os.path.join(directory, name)), image)\n",
    "\n",
    "Augmented_df.to_csv(\"AugmentedTrain19&15.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:32:32.205173Z",
     "start_time": "2024-05-04T08:50:57.096264Z"
    }
   },
   "id": "16c64495f41b4321",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                            image  level\n0                    000c1434d8d7      2\n1      000c1434d8d7_rotate180.jpg      2\n2      000c1434d8d7_rotate270.jpg      2\n3       000c1434d8d7_rotate90.jpg      2\n4                    001639a390f0      4\n...                           ...    ...\n72302                ffd97f8cd5aa      0\n72303                ffec9a18a3ce      2\n72304  ffec9a18a3ce_rotate180.jpg      2\n72305  ffec9a18a3ce_rotate270.jpg      2\n72306   ffec9a18a3ce_rotate90.jpg      2\n\n[72307 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000c1434d8d7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000c1434d8d7_rotate180.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000c1434d8d7_rotate270.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000c1434d8d7_rotate90.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001639a390f0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>72302</th>\n      <td>ffd97f8cd5aa</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>72303</th>\n      <td>ffec9a18a3ce</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>72304</th>\n      <td>ffec9a18a3ce_rotate180.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>72305</th>\n      <td>ffec9a18a3ce_rotate270.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>72306</th>\n      <td>ffec9a18a3ce_rotate90.jpg</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>72307 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Augmented_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:32:50.152076Z",
     "start_time": "2024-05-04T09:32:50.005473Z"
    }
   },
   "id": "ea5a5053a6cf51d8",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "level\n0    27615\n1    11252\n2    25164\n3     4264\n4     4012\ndtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot = Augmented_df.pivot(columns='level', values='image')\n",
    "df_pivot.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:32:58.472733Z",
     "start_time": "2024-05-04T09:32:58.374050Z"
    }
   },
   "id": "c0ef49dc423c46f4",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Augmented_df.to_csv(\"AugmentedTrain19&15.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T00:01:50.916094Z",
     "start_time": "2024-04-17T00:01:50.749535Z"
    }
   },
   "id": "fb704420cd3fd6c",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Applying SMOTE\n",
    "\n",
    "As seen above the imbalance in classes is still very high even after we augmented them, since GANs produce some faulty images in terms of fundus photography, we have to move towards SMOTE to balance the classes to finally move towards model training.\n",
    "- SMOTE needs numerical data for both images and their classes so we replace the names of images with their respective indices so after the imbalance is resolved we will bring back the names\n",
    "- `Name_to_index` and `index_to_name` variables are used for numeric and string transitions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc7f7ca9a5ae0e9d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "        image  level\n0           0      2\n1           1      2\n2           2      2\n3           3      2\n4           4      4\n...       ...    ...\n138070  69196      4\n138071  31266      4\n138072  71881      4\n138073  47465      4\n138074   9260      4\n\n[138075 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>138070</th>\n      <td>69196</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>138071</th>\n      <td>31266</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>138072</th>\n      <td>71881</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>138073</th>\n      <td>47465</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>138074</th>\n      <td>9260</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>138075 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = Augmented_df\n",
    "y =Augmented_df['level']\n",
    "\n",
    "name_to_index = dict(enumerate(X.image))\n",
    "index_to_name = {v: k for k, v in name_to_index.items()}\n",
    "\n",
    "X.drop('level', axis = 1)\n",
    "def replace_values(x):\n",
    "    return index_to_name.get(x)\n",
    "\n",
    "X = X['image'].apply(replace_values)\n",
    "print(X.dtype)\n",
    "X = pd.DataFrame({'image': X})\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "resampled_data = pd.DataFrame(X_resampled, columns=['image'])\n",
    "resampled_data['level'] = y_resampled\n",
    "\n",
    "resampled_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T15:30:15.454098Z",
     "start_time": "2024-05-04T15:30:15.085839Z"
    }
   },
   "id": "cad51aaa121f3669",
   "execution_count": 150
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transitioning back to string names of the images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f05ec4c139c52b8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                             image  level\n0                     000c1434d8d7      2\n1       000c1434d8d7_rotate180.jpg      2\n2       000c1434d8d7_rotate270.jpg      2\n3        000c1434d8d7_rotate90.jpg      2\n4                     001639a390f0      4\n...                            ...    ...\n138070  a76b69e443ce_rotate180.jpg      4\n138071     28948_left_rotate90.jpg      4\n138072  f2094a20b275_rotate270.jpg      4\n138073    38856_left_rotate270.jpg      4\n138074                  15376_left      4\n\n[138075 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000c1434d8d7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000c1434d8d7_rotate180.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000c1434d8d7_rotate270.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000c1434d8d7_rotate90.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001639a390f0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>138070</th>\n      <td>a76b69e443ce_rotate180.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>138071</th>\n      <td>28948_left_rotate90.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>138072</th>\n      <td>f2094a20b275_rotate270.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>138073</th>\n      <td>38856_left_rotate270.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>138074</th>\n      <td>15376_left</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>138075 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_indices_with_original_names(x):\n",
    "    return name_to_index.get(x)\n",
    "\n",
    "resampled_data['image'] = resampled_data['image'].apply(replace_indices_with_original_names)\n",
    "\n",
    "resampled_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T15:41:45.554970Z",
     "start_time": "2024-05-04T15:41:45.262853Z"
    }
   },
   "id": "d25708b0ada37d7a",
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "resampled_data.to_csv('BalancedDataSMOTEwithRelativeNames.csv', index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T15:53:38.054856Z",
     "start_time": "2024-05-04T15:53:37.883467Z"
    }
   },
   "id": "37c8447b87492f5a",
   "execution_count": 176
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Conv2d, MaxPooling2D\n",
    "model = Sequential()\n",
    "\n",
    "model.add()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dd56a44a7947213"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.16.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.3.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (23.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.25.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.31.0)\r\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (65.5.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.10.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.62.2)\r\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.16.2)\r\n",
      "Requirement already satisfied: keras>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.3.3)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.37.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.26.4)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\r\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.4)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T09:56:46.767037Z",
     "start_time": "2024-05-05T09:56:40.576123Z"
    }
   },
   "id": "a97d6eb826e6f127",
   "execution_count": 181
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "be34d59e46a9ea9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
